{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from classes.agent import Agent\n",
    "from classes.ou_network import OU_Network\n",
    "from classes.internal_state import Normative_DIS\n",
    "from classes.action_state import Discounted_gain_soft_horizon_TSAS\n",
    "from classes.sensory_state import Omniscient_ST\n",
    "\n",
    "from classes.experiment import Experiment\n",
    "\n",
    "from methods.policies import softmax_policy_init\n",
    "from methods.empirical_priors import discrete_empirical_priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import behavioural experiment\n",
    "with open('/home/vbtesh/documents/CompProjects/vbtCogSci/csl2analysis/data/csl_2_modelling_data.obj', 'rb') as inFile:\n",
    "    modelling_data = pickle.load(inFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_key = '5ef109c89196fa6d5cf6c005'\n",
    "conditions = ['generic', 'congruent', 'incongruent', 'implausible']\n",
    "cond = conditions[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['trial_index', 'data', 'inters', 'inters_fit', 'standard_order', 'in_trial_order', 'prior', 'posterior', 'ground_truth', 'links_hist'])\n",
      "[-1.  0. -1.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "fitting = True # If false, no data will be used \n",
    "if fitting:\n",
    "    ## Data from trial\n",
    "    part_data = modelling_data[part_key]['trials'][cond]\n",
    "    print(part_data.keys())\n",
    "    \n",
    "    posterior = part_data['posterior']\n",
    "    data = part_data['data']\n",
    "    inters = part_data['inters']\n",
    "    inters_fit = part_data['inters_fit']\n",
    "    judgement_data = part_data['links_hist']\n",
    "\n",
    "print(part_data['posterior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# General model parameters (true for all trials)\n",
    "if fitting:\n",
    "    N = data.shape[0] - 1\n",
    "    K = data.shape[1]\n",
    "else:\n",
    "    N = 100\n",
    "    K = 3\n",
    "links = np.array([-1, -0.5, 0, 0.5, 1])\n",
    "theta = 0.5\n",
    "dt = 0.2\n",
    "sigma = 1 \n",
    "# Set up priors\n",
    "flat_prior = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "flat_prior = np.tile(flat_prior, (6, 1))\n",
    "random_prior = np.random.rand(6, 5)\n",
    "random_prior = random_prior / random_prior.sum(axis=1).reshape((6, 1))\n",
    "prior_perfect = np.array([[1, 0, 0, 0, 0],\n",
    "                             [0, 0, 1, 0, 0],\n",
    "                             [0, 0, 1, 0, 0],\n",
    "                             [1, 0, 0, 0, 0],\n",
    "                             [0, 0, 1, 0, 0],\n",
    "                             [0, 0, 1, 0, 0]])\n",
    "# Emprical Priors\n",
    "part_map = part_data['prior'] # Participant's maximum a priori\n",
    "temp = 3/2 # Must be explored further\n",
    "empirical_priors, entropy = discrete_empirical_priors(part_map, links, temp)\n",
    "## Final prior assignment\n",
    "prior = empirical_priors\n",
    "# Prior sample size\n",
    "## MUST BE 1 WHEN USING EMPIRICAL PRIORS\n",
    "prior_sample_size = 1\n",
    "#print(prior**prior_sample_size)\n",
    "# Ground truth model\n",
    "## Import from behavioural experiment\n",
    "gt_behavioural_exp = part_data['ground_truth']\n",
    "## Any model as np.ndarray\n",
    "custom_model = np.array([-1, 0, .0, -1, 0, 0])\n",
    "## Final ground truth assignment\n",
    "true_model = gt_behavioural_exp\n",
    "# Action parameters\n",
    "## Number of model to sample from the posterior\n",
    "C = 1\n",
    "## Different action possibility\n",
    "poss_actions = np.arange(-100, 100)\n",
    "poss_actions = np.array([85, 45, 0, -45, -85])\n",
    "poss_actions = np.arange(-100, 101, step=10)\n",
    "## Define action length (TO BE REFINED FOR FITTING DATA)\n",
    "action_len = 5 \n",
    "## Policy for action selection from action values\n",
    "policy_funcs = softmax_policy_init(1) # Returns three function: sample, pmf, params\n",
    "## Parameters\n",
    "epsilon = 1e-2 # Certainty threshold: agent stops intervening after entropy goes below epsilon\n",
    "knowledge = False  # Can be a model as nd.array, True for perfect knowledge, 'random' for random sampling and False for posterior based sampling\n",
    "## Special parameters for tree searches\n",
    "horizon = 1e-1 # For soft horizon discounted gain\n",
    "discount = 0.1 # For soft horizon discounted gain\n",
    "depth = 0 # Horizon for hard horizon undiscounted gain\n",
    "## General behaviour parameter\n",
    "behaviour = 'random'   # Can be 'obs', 'random' or 'actor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensory_state = Omniscient_ST(N, K)\n",
    "action_state = Discounted_gain_soft_horizon_TSAS(N, K, behaviour, poss_actions, action_len, policy_funcs, epsilon, C, knowledge, discount, horizon)\n",
    "internal_state = Normative_DIS(N, K, prior, prior_sample_size, links, dt, theta, sigma, sample_params=True)\n",
    "external_state = OU_Network(N, K, true_model, theta, dt, sigma)\n",
    "\n",
    "agent = Agent(N, sensory_state, internal_state, action_state)\n",
    "\n",
    "if fitting:\n",
    "    external_state.load_trial_data(data)\n",
    "    action_state.load_action_data(inters, inters_fit, data)\n",
    "    internal_state.load_judgement_data(judgement_data, posterior)\n",
    "\n",
    "experiment = Experiment(agent, external_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 Current MAP: [-1.   0.5  1.   1.   0.   1. ] Current LL: -4.1588830833596715\n",
      "Iter: 10 Current MAP: [-1.   0.5 -1.   0.5  0.5  1. ] Current LL: -37.42994775023704\n",
      "Iter: 20 Current MAP: [ 1.   1.   0.  -1.   0.5  1. ] Current LL: -74.85989550047407\n",
      "Iter: 30 Current MAP: [ 1.   1.   0.  -1.   0.5  1. ] Current LL: [-238.45225144]\n",
      "Iter: 40 Current MAP: [ 1.   1.   0.  -1.   0.5  1. ] Current LL: [-280.04108227]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1272/368005413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/CompProjects/vbtCogSci/active_learning_agent/classes/experiment.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, final_judgement)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Learn from the new state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintervention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/CompProjects/vbtCogSci/active_learning_agent/classes/agent.py\u001b[0m in \u001b[0;36mfit_learn\u001b[0;34m(self, external_state, intervention)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Update internal states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mlog_prob_judgement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sensory_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintervention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintervention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_likelihood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlog_prob_judgement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/CompProjects/vbtCogSci/active_learning_agent/classes/internal_state.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, sensory_state, intervention)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mjudgement_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_PMF_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_likelihood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mjudgement_log_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mjudgement_log_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (0,)"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "if fitting:\n",
    "    experiment.fit(posterior)\n",
    "else:\n",
    "    experiment.run()\n",
    "\n",
    "#experiment.entropy_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-48245.87949599 -21604.54075854 -20257.3368764  ... -24768.98664172\n",
      " -18417.89534877 -41502.72154174]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.00000000e+000, 4.38976664e-204],\n",
       "       [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.00000000e+000, 4.38976664e-204],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.00000000e+000, 4.38976664e-204]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL = internal_state._posterior_params_history[150]\n",
    "LL_n = LL - np.amax(LL)\n",
    "lh = np.exp(LL_n) / np.exp(LL_n).sum()\n",
    "\n",
    "print(lh)\n",
    "print(LL_n)\n",
    "\n",
    "internal_state._models_to_links(lh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting\n",
    "\n",
    "When fitting, we have data about the external states, the interventions a participant made, i.e. action states, and their judgement or any other direct measure of their internal states. \n",
    "\n",
    "By definition, sensory states are never observed because they are always implicit. In many cases such as in a control environment, internal states will not be directly observed using judgement but should be inferred from actions states\n",
    "\n",
    "The dependencies between all core modules imply that fitting a dataset of observations, actions and judgments is only valid for the current global parametrisation of the agent, i.e. the collection of internal, sensory and action states. We can compare how things change when changing one of the modules but we cannot seperate the likelihoods over the different modules.\n",
    "\n",
    "## Where should the data be stored when fitting?\n",
    "\n",
    "Basically the question is programming related and asks how should the data be split when initialising the states of the experiment. It could be a seperate method \"load_data\" called seperately from initialising the agent and the external states. Given the current way the states objects are structured, it creates an inconsistency where parameters have to be specified before hand before being overwritten.\n",
    "\n",
    "# Questions\n",
    "\n",
    "## Number of datapoints\n",
    "\n",
    "The log likelihood is highly sensitive to the number of datapoints. If we assume that the participant cannot observe all datapoints for instance, we artificially reduce the log likelihood. So what can we do?\n",
    "\n",
    "What do we do when encountering negative infinities, i.e. probability 0. Conceptually it can make sense but it is still highly dependent on the number of datapoints again as some discrete models will simply converge numerically to point masses given enough datapoints. Can we simply conclude to the extreme unlikeliness of this model?\n",
    "\n",
    "## Number of parameters\n",
    "\n",
    "Also the number of parameters in a model is not straightforward: in the discrete case model representation has 15625 and links representation has 30, but one is a direct function of the other without adding any additional parameters. In a continuous case, easier to represent as it is the collection of parameters of the PDF."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
