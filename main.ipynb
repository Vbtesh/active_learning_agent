{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from classes.agent import Agent\n",
    "from classes.ou_network import OU_Network\n",
    "from classes.internal_state import Normative_DIS\n",
    "from classes.action_state import Discounted_gain_soft_horizon_TSAS\n",
    "from classes.sensory_state import Omniscient_ST\n",
    "\n",
    "from classes.experiment import Experiment\n",
    "\n",
    "from methods.policies import softmax_policy_init\n",
    "from methods.empirical_priors import discrete_empirical_priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import behavioural experiment\n",
    "with open('/home/vbtesh/Documents/CompProjects/vbtCogSci/csl2analysis/data/csl_2_modelling_data.obj', 'rb') as inFile:\n",
    "    modelling_data = pickle.load(inFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_key = '5ef109c89196fa6d5cf6c005'\n",
    "conditions = ['generic', 'congruent', 'incongruent', 'implausible']\n",
    "cond = conditions[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['trial_index', 'data', 'inters', 'inters_fit', 'standard_order', 'in_trial_order', 'prior', 'posterior', 'ground_truth'])\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "fitting = True # If false, no data will be used \n",
    "if fitting:\n",
    "    ## Data from trial\n",
    "    part_data = modelling_data[part_key]['trials'][cond]\n",
    "    print(part_data.keys())\n",
    "    \n",
    "    posterior = part_data['posterior']\n",
    "    data = part_data['data']\n",
    "    inters = part_data['inters']\n",
    "    inters_fit = part_data['inters_fit']\n",
    "# General model parameters (true for all trials)\n",
    "if fitting:\n",
    "    N = data.shape[0] - 1\n",
    "    K = data.shape[1]\n",
    "else:\n",
    "    N = 100\n",
    "    K = 3\n",
    "links = np.array([-1, -0.5, 0, 0.5, 1])\n",
    "theta = 0.5\n",
    "dt = 0.2\n",
    "sigma = 1 \n",
    "# Set up priors\n",
    "flat_prior = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "flat_prior = np.tile(flat_prior, (6, 1))\n",
    "random_prior = np.random.rand(6, 5)\n",
    "prior_perfect = np.array([[1, 0, 0, 0, 0],\n",
    "                             [0, 0, 1, 0, 0],\n",
    "                             [0, 0, 1, 0, 0],\n",
    "                             [1, 0, 0, 0, 0],\n",
    "                             [0, 0, 1, 0, 0],\n",
    "                             [0, 0, 1, 0, 0]])\n",
    "# Emprical Priors\n",
    "part_map = part_data['prior'] # Participant's maximum a priori\n",
    "temp = 3/2 # Must be explored further\n",
    "empirical_priors, entropy = discrete_empirical_priors(part_map, links, temp)\n",
    "## Final prior assignment\n",
    "prior = empirical_priors\n",
    "# Prior sample size\n",
    "## MUST BE 1 WHEN USING EMPIRICAL PRIORS\n",
    "prior_sample_size = 1\n",
    "#print(prior**prior_sample_size)\n",
    "# Ground truth model\n",
    "## Import from behavioural experiment\n",
    "gt_behavioural_exp = part_data['ground_truth']\n",
    "## Any model as np.ndarray\n",
    "custom_model = np.array([-1, 0, .0, -1, 0, 0])\n",
    "## Final ground truth assignment\n",
    "true_model = gt_behavioural_exp\n",
    "# Action parameters\n",
    "## Number of model to sample from the posterior\n",
    "C = 1\n",
    "## Different action possibility\n",
    "poss_actions = np.arange(-100, 100)\n",
    "poss_actions = np.array([85, 45, 0, -45, -85])\n",
    "poss_actions = np.arange(-100, 101, step=10)\n",
    "## Define action length (TO BE REFINED FOR FITTING DATA)\n",
    "action_len = 5 \n",
    "## Policy for action selection from action values\n",
    "policy_funcs = softmax_policy_init(1) # Returns three function: sample, pmf, params\n",
    "## Parameters\n",
    "epsilon = 1e-2 # Certainty threshold: agent stops intervening after entropy goes below epsilon\n",
    "knowledge = False  # Can be a model as nd.array, True for perfect knowledge, 'random' for random sampling and False for posterior based sampling\n",
    "## Special parameters for tree searches\n",
    "horizon = 1e-1 # For soft horizon discounted gain\n",
    "discount = 0.1 # For soft horizon discounted gain\n",
    "depth = 0 # Horizon for hard horizon undiscounted gain\n",
    "## General behaviour parameter\n",
    "behaviour = 'actor'   # Can be 'obs', 'random' or 'actor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensory_state = Omniscient_ST(N, K)\n",
    "action_state = Discounted_gain_soft_horizon_TSAS(N, K, behaviour, poss_actions, action_len, policy_funcs, epsilon, C, knowledge, discount, horizon)\n",
    "internal_state = Normative_DIS(N, K, prior, prior_sample_size, links, dt, theta, sigma, sample_params=True)\n",
    "\n",
    "agent = Agent(N, sensory_state, internal_state, action_state)\n",
    "\n",
    "if fitting:\n",
    "    external_state = OU_Network(N, K, true_model, theta, dt, sigma, data=data, inters=inters, inters_fit=inters_fit)\n",
    "else:\n",
    "    external_state = OU_Network(N, K, true_model, theta, dt, sigma)\n",
    "\n",
    "experiment = Experiment(agent, external_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute action values, C= 0 Model n: 0 Sampled graph: [-1.   1.   1.   1.   0.5  1. ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for axis 0 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31771/368005413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompProjects/vbtCogSci/active_learning_agent/classes/experiment.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, final_judgement)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Fit action to fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Update external state using action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompProjects/vbtCogSci/active_learning_agent/classes/agent.py\u001b[0m in \u001b[0;36mfit_action\u001b[0;34m(self, external_state, action, action_fit)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         log_prob_action = self._action_state.fit(action, \n\u001b[0m\u001b[1;32m     54\u001b[0m                                                  \u001b[0maction_fit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                                  \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompProjects/vbtCogSci/active_learning_agent/classes/action_state.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, action, action_fit, external_state, sensory_state, internal_state)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# Compute policy params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0maction_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pmf_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Update hitory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompProjects/vbtCogSci/active_learning_agent/methods/policies.py\u001b[0m in \u001b[0;36mpmf_softmax_policy\u001b[0;34m(action_taken, action_values)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpmf_softmax_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_taken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_taken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparams_softmax_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 0 with size 64"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "if fitting:\n",
    "    experiment.fit(posterior)\n",
    "else:\n",
    "    experiment.run()\n",
    "\n",
    "#experiment.entropy_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-48245.87949599 -21604.54075854 -20257.3368764  ... -24768.98664172\n",
      " -18417.89534877 -41502.72154174]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.00000000e+000, 4.38976664e-204],\n",
       "       [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.00000000e+000, 4.38976664e-204],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.00000000e+000, 4.38976664e-204]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL = internal_state._posterior_params_history[150]\n",
    "LL_n = LL - np.amax(LL)\n",
    "lh = np.exp(LL_n) / np.exp(LL_n).sum()\n",
    "\n",
    "print(lh)\n",
    "print(LL_n)\n",
    "\n",
    "internal_state._models_to_links(lh)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
